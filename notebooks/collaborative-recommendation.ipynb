{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/08 11:40:12 WARN Utils: Your hostname, ubuntu20 resolves to a loopback address: 127.0.1.1; using 192.168.0.234 instead (on interface wlp0s20f3)\n",
      "24/08/08 11:40:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/08 11:40:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/08/08 11:40:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Start spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"10g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rating dataset\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"Username\", StringType(), True),\n",
    "    StructField(\"anime_id\", IntegerType(), True),\n",
    "    StructField(\"Anime Title\", StringType(), True),\n",
    "    StructField(\"rating\", IntegerType(), True)])\n",
    "\n",
    "df = spark.read.csv('../dataset/myanimelist-dataset/processed-dataset/users-score-2023.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- Username: string (nullable = true)\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- Anime Title: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+------+\n",
      "|user_id|Username|anime_id|         Anime Title|rating|\n",
      "+-------+--------+--------+--------------------+------+\n",
      "|      1|   Xinil|      21|           One Piece|     9|\n",
      "|      1|   Xinil|      48|         .hack//Sign|     7|\n",
      "|      1|   Xinil|     320|              A Kite|     5|\n",
      "|      1|   Xinil|      49|    Aa! Megami-sama!|     8|\n",
      "|      1|   Xinil|     304|Aa! Megami-sama! ...|     8|\n",
      "|      1|   Xinil|     306|Abenobashi Mahou☆...|     8|\n",
      "|      1|   Xinil|      53|       Ai Yori Aoshi|     7|\n",
      "|      1|   Xinil|      47|               Akira|     5|\n",
      "|      1|   Xinil|     591|      Amaenaide yo!!|     6|\n",
      "|      1|   Xinil|      54|   Appleseed (Movie)|     7|\n",
      "+-------+--------+--------+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24321734"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(rating)|\n",
      "+-----------------+\n",
      "|7.623071159317835|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculating the average score\n",
    "df.agg({ \"rating\": \"avg\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "270031"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of distinct users who have ratings\n",
    "num_users = df.select(\"user_id\").distinct().count()\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16497"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of distinct rated animes\n",
    "num_animes = df.select(\"anime_id\").distinct().count()\n",
    "num_animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings:  24321734\n",
      "Sparsity:  0.994540210043757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate sparsity\n",
    "num_ratings = df.count()\n",
    "print(\"Number of ratings: \", num_ratings)\n",
    "\n",
    "total_expect_rating = num_users * num_animes\n",
    "sparsity = (total_expect_rating - num_ratings) / total_expect_rating\n",
    "print(\"Sparsity: \", sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, test_set) = df.randomSplit([0.8, 0.2], seed=1256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set:  19455312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in test set:  4866422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in training set: \", train_set.count())\n",
    "print(\"Number of samples in test set: \", test_set.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameters for ALS\n",
    "RANK = 10\n",
    "MAX_ITER = 10\n",
    "REG_PARAM = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/25 12:34:49 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/07/25 12:34:50 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = als.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 172:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------------------+------+----------+\n",
      "|user_id|Username|anime_id|         Anime Title|rating|prediction|\n",
      "+-------+--------+--------+--------------------+------+----------+\n",
      "|      1|   Xinil|       5|Cowboy Bebop: Ten...|     8|  8.093723|\n",
      "|      1|   Xinil|      19|             Monster|     9|  8.411947|\n",
      "|      1|   Xinil|      30|Neon Genesis Evan...|    10| 7.5512943|\n",
      "|      1|   Xinil|      53|       Ai Yori Aoshi|     7| 6.8196783|\n",
      "|      1|   Xinil|      60|       Chrno Crusade|     8| 7.3844004|\n",
      "+-------+--------+--------+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 248:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.2344622964227925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anime dataset\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"anime_id\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"English name\", StringType(), True),\n",
    "    StructField(\"Other name\", StringType(), True),\n",
    "    StructField(\"Score\", FloatType(), True),\n",
    "    StructField(\"Genres\", StringType(), True),\n",
    "    StructField(\"Synopsis\", StringType(), True),\n",
    "    StructField(\"Type\", StringType(), True),\n",
    "    StructField(\"Episodes\", FloatType(), True),\n",
    "    StructField(\"Aired\", StringType(), True),\n",
    "    StructField(\"Premiered\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"Producers\", StringType(), True),\n",
    "    StructField(\"Licensors\", StringType(), True),\n",
    "    StructField(\"Studios\", StringType(), True),\n",
    "    StructField(\"Source\", StringType(), True),\n",
    "    StructField(\"Duration\", StringType(), True),\n",
    "    StructField(\"Rating\", StringType(), True),\n",
    "    StructField(\"Rank\", FloatType(), True),\n",
    "    StructField(\"Popularity\", IntegerType(), True),\n",
    "    StructField(\"Favorites\", IntegerType(), True),\n",
    "    StructField(\"Scored By\", FloatType(), True),\n",
    "    StructField(\"Members\", FloatType(), True),\n",
    "    StructField(\"Image URL\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_anime = spark.read.csv('../dataset/myanimelist-dataset/processed-dataset/anime-dataset-2023.csv', header=True, schema=schema, multiLine=True, quote='\\\"', escape='\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24905"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anime.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "popularity_threshold = 200\n",
    "df_anime = df_anime.where(f\"Members >= {popularity_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+---------------------------+-----+--------------------+--------------------+-----+--------+--------------------+-----------+---------------+--------------------+--------------------+--------------+--------+-------------+--------------------+------+----------+---------+---------+---------+--------------------+\n",
      "|anime_id|                Name|        English name|                 Other name|Score|              Genres|            Synopsis| Type|Episodes|               Aired|  Premiered|         Status|           Producers|           Licensors|       Studios|  Source|     Duration|              Rating|  Rank|Popularity|Favorites|Scored By|  Members|           Image URL|\n",
      "+--------+--------------------+--------------------+---------------------------+-----+--------------------+--------------------+-----+--------+--------------------+-----------+---------------+--------------------+--------------------+--------------+--------+-------------+--------------------+------+----------+---------+---------+---------+--------------------+\n",
      "|       1|        Cowboy Bebop|        Cowboy Bebop|         カウボーイビバップ| 8.75|Action, Award Win...|Crime is timeless...|   TV|    26.0|Apr 3, 1998 to Ap...|spring 1998|Finished Airing|       Bandai Visual|Funimation, Banda...|       Sunrise|Original|24 min per ep|R - 17+ (violence...|  41.0|        43|    78525| 914193.0|1771505.0|https://cdn.myani...|\n",
      "|       5|Cowboy Bebop: Ten...|Cowboy Bebop: The...|カウボーイビバップ 天国の扉| 8.38|      Action, Sci-Fi|Another day, anot...|Movie|     1.0|         Sep 1, 2001|    UNKNOWN|Finished Airing|Sunrise, Bandai V...|Sony Pictures Ent...|         Bones|Original|  1 hr 55 min|R - 17+ (violence...| 189.0|       602|     1448| 206248.0| 360978.0|https://cdn.myani...|\n",
      "|       6|              Trigun|              Trigun|                 トライガン| 8.22|Action, Adventure...|Vash the Stampede...|   TV|    26.0|Apr 1, 1998 to Se...|spring 1998|Finished Airing|Victor Entertainment|Funimation, Geneo...|      Madhouse|   Manga|24 min per ep|PG-13 - Teens 13 ...| 328.0|       246|    15035| 356739.0| 727252.0|https://cdn.myani...|\n",
      "|       7|  Witch Hunter Robin|  Witch Hunter Robin|       Witch Hunter ROBI...| 7.25|Action, Drama, My...|Robin Sena is a p...|   TV|    26.0|Jul 3, 2002 to De...|summer 2002|Finished Airing|Bandai Visual, De...|Funimation, Banda...|       Sunrise|Original|25 min per ep|PG-13 - Teens 13 ...|2764.0|      1795|      613|  42829.0| 111931.0|https://cdn.myani...|\n",
      "|       8|      Bouken Ou Beet|Beet the Vandel B...|               冒険王ビィト| 6.94|Adventure, Fantas...|It is the dark ce...|   TV|    52.0|Sep 30, 2004 to S...|  fall 2004|Finished Airing|    TV Tokyo, Dentsu|Illumitoon Entert...|Toei Animation|   Manga|23 min per ep|       PG - Children|4240.0|      5126|       14|   6413.0|  15001.0|https://cdn.myani...|\n",
      "+--------+--------------------+--------------------+---------------------------+-----+--------------------+--------------------+-----+--------+--------------------+-----------+---------------+--------------------+--------------------+--------------+--------+-------------+--------------------+------+----------+---------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_anime.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing user details dataframe\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Mal ID\", IntegerType(), True),\n",
    "    StructField(\"Username\", StringType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Birthday\", StringType(), True),\n",
    "    StructField(\"Location\", StringType(), True),\n",
    "    StructField(\"Joined\", StringType(), True),\n",
    "    StructField(\"Days Watched\", FloatType(), True),\n",
    "    StructField(\"Mean Score\", FloatType(), True),\n",
    "    StructField(\"Watching\", FloatType(), True),\n",
    "    StructField(\"Completed\", FloatType(), True),\n",
    "    StructField(\"On Hold\", FloatType(), True),\n",
    "    StructField(\"Dropped\", FloatType(), True),\n",
    "    StructField(\"Plan to Watch\", FloatType(), True),\n",
    "    StructField(\"Total Entries\", FloatType(), True),\n",
    "    StructField(\"Rewatched\", FloatType(), True),\n",
    "    StructField(\"Episodes Watched\", FloatType(), True)\n",
    "])\n",
    "\n",
    "df_user = spark.read.csv(\"../dataset/myanimelist-dataset/processed-dataset/users-details-2023.csv\", header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+--------------------+--------------------+--------------------+------------+----------+--------+---------+-------+-------+-------------+-------------+---------+----------------+\n",
      "|Mal ID|Username|Gender|            Birthday|            Location|              Joined|Days Watched|Mean Score|Watching|Completed|On Hold|Dropped|Plan to Watch|Total Entries|Rewatched|Episodes Watched|\n",
      "+------+--------+------+--------------------+--------------------+--------------------+------------+----------+--------+---------+-------+-------+-------------+-------------+---------+----------------+\n",
      "|     1|   Xinil|  Male|1985-03-04T00:00:...|          California|2004-11-05T00:00:...|       142.3|      7.37|     1.0|    233.0|    8.0|   93.0|         64.0|        399.0|     60.0|          8458.0|\n",
      "|     3| Aokaado|  Male|                NULL|        Oslo, Norway|2004-11-11T00:00:...|        68.6|      7.34|    23.0|    137.0|   99.0|   44.0|         40.0|        343.0|     15.0|          4072.0|\n",
      "|     4| Crystal|Female|                NULL|Melbourne, Australia|2004-11-13T00:00:...|       212.8|      6.68|    16.0|    636.0|  303.0|    0.0|         45.0|       1000.0|     10.0|         12781.0|\n",
      "|     9|  Arcane|  NULL|                NULL|                NULL|2004-12-05T00:00:...|        30.0|      7.71|     5.0|     54.0|    4.0|    3.0|          0.0|         66.0|      0.0|          1817.0|\n",
      "|    18|     Mad|  NULL|                NULL|                NULL|2005-01-03T00:00:...|        52.0|      6.27|     1.0|    114.0|   10.0|    5.0|         23.0|        153.0|     42.0|          3038.0|\n",
      "+------+--------+------+--------------------+--------------------+--------------------+------------+----------+--------+---------+-------+-------+-------------+-------------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36175, 8353, 39967, 50587, 49654, 35433, 37857, 50681, 51503, 18137]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user's id to recommend animes for\n",
    "user_id=4\n",
    "number_of_recommendations = 10\n",
    "\n",
    "# convert user id to Dataframe\n",
    "user = spark.createDataFrame([Row(user_id=user_id)])\n",
    "# get recommendations\n",
    "recommendations = model.recommendForUserSubset(user, number_of_recommendations)\n",
    "# convert recommendations from Pyspark Dataframe to Pandas Dataframe\n",
    "recommendation_pd = recommendations.toPandas()\n",
    "# Get recommended anime ids\n",
    "anime_ids = [recommendation['anime_id'] for recommendation in recommendation_pd['recommendations'][0]]\n",
    "anime_ids\n",
    "# filter to get recommended data from anime dataset\n",
    "# recommended_anime = df_anime.where(F.col(\"anime_id\").isin(anime_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------------------------------------------------+------------------------+-------+-----+\n",
      "|anime_id|Name                                                                 |Genres                  |Type   |Score|\n",
      "+--------+---------------------------------------------------------------------+------------------------+-------+-----+\n",
      "|8353    |Ketsuinu                                                             |Comedy                  |TV     |6.38 |\n",
      "|34852   |Pikaia!!                                                             |Drama, Slice of Life    |TV     |5.77 |\n",
      "|35433   |Jakusansei Million Arthur: Forever Kakusansei Million Arthur         |Comedy, Fantasy, Ecchi  |ONA    |5.5  |\n",
      "|36175   |Diary                                                                |UNKNOWN                 |Music  |6.09 |\n",
      "|37857   |Guilty Gear X                                                        |Action                  |Special|5.71 |\n",
      "|39967   |Shinkansen Henkei Robo Shinkalion: Mirai kara Kita Shinsoku no ALFA-X|Action, Sci-Fi          |Movie  |6.54 |\n",
      "|49654   |Hakubunchou no Shiro                                                 |Slice of Life           |ONA    |6.16 |\n",
      "|50090   |Inko Colors the Animation 2                                          |Adventure, Slice of Life|ONA    |6.05 |\n",
      "|50587   |Gridman Universe                                                     |Action, Sci-Fi          |Movie  |6.91 |\n",
      "|50681   |Baby-Hamitang                                                        |UNKNOWN                 |TV     |6.38 |\n",
      "+--------+---------------------------------------------------------------------+------------------------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show recommendations\n",
    "recommended_anime.select(\"anime_id\", \"Name\", \"Genres\", \"Type\", \"Score\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 341:============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------------------+------------------------------------------------+------+\n",
      "|anime_id|Name                               |Genres                                          |rating|\n",
      "+--------+-----------------------------------+------------------------------------------------+------+\n",
      "|150     |Blood+                             |Action, Drama, Horror, Mystery, Supernatural    |9     |\n",
      "|31043   |Boku dake ga Inai Machi            |Mystery, Supernatural, Suspense                 |9     |\n",
      "|10800   |Chihayafuru                        |Drama, Sports                                   |9     |\n",
      "|14397   |Chihayafuru 2                      |Drama, Sports                                   |9     |\n",
      "|14741   |Chuunibyou demo Koi ga Shitai!     |Comedy, Romance                                 |9     |\n",
      "|2759    |Evangelion: 1.0 You Are (Not) Alone|Action, Award Winning, Drama, Sci-Fi            |9     |\n",
      "|121     |Fullmetal Alchemist                |Action, Adventure, Award Winning, Drama, Fantasy|9     |\n",
      "|127     |Gate Keepers                       |Action, Comedy, Fantasy, Sci-Fi                 |9     |\n",
      "|240     |Genshiken                          |Comedy, Slice of Life                           |9     |\n",
      "|1571    |Ghost Hunt                         |Horror, Mystery, Supernatural                   |9     |\n",
      "|934     |Higurashi no Naku Koro ni          |Horror, Mystery, Supernatural, Suspense         |9     |\n",
      "|1889    |Higurashi no Naku Koro ni Kai      |Mystery, Supernatural, Suspense                 |9     |\n",
      "|135     |Hikaru no Go                       |Comedy, Drama, Supernatural                     |9     |\n",
      "|9760    |Hoshi wo Ou Kodomo                 |Adventure, Fantasy, Romance                     |9     |\n",
      "|153     |Juuni Kokuki                       |Action, Adventure, Fantasy                      |9     |\n",
      "|7054    |Kaichou wa Maid-sama!              |Comedy, Romance                                 |9     |\n",
      "|10396   |Ben-To                             |Action, Comedy, Gourmet                         |8     |\n",
      "|13535   |Binbougami ga!                     |Comedy, Supernatural                            |8     |\n",
      "|2986    |Bamboo Blade                       |Comedy, Sports                                  |8     |\n",
      "|7059    |Black★Rock Shooter (OVA)           |Action, Drama                                   |8     |\n",
      "+--------+-----------------------------------+------------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get anime rated by user\n",
    "anime_rated_by_specific_user = df.where(f\"user_id = {user_id}\").join(df_anime, df.anime_id == df_anime.anime_id).orderBy(df.rating.desc()).select(df_anime.anime_id, df_anime.Name, df_anime.Genres, df.rating)\n",
    "anime_rated_by_specific_user = anime_rated_by_specific_user.filter(anime_rated_by_specific_user['rating'] >= 5)\n",
    "anime_rated_by_specific_user = anime_rated_by_specific_user.filter(anime_rated_by_specific_user['rating'] <= 9)\n",
    "anime_rated_by_specific_user.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/08 11:49:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/08/08 11:49:56 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "\n",
    "# Build new model to tuning\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Construct a grid of parameters to search over the list of ranks\n",
    "# param_grid = ParamGridBuilder().addGrid(als.rank, [10, 25, 50],).build()\n",
    "param_grid = ParamGridBuilder().addGrid(als.rank, [10],).build()\n",
    "\n",
    "# Use rmse to see how well a fitted model performs\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\")\n",
    "\n",
    "crossval = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "cv_model = crossval.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = cv_model.bestModel\n",
    "# Get the rank of the best model\n",
    "best_model.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "best_model.save(\"../models/als_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 20|[0.3963369, 1.125...|\n",
      "| 30|[-0.86721945, 1.4...|\n",
      "| 50|[-0.26204997, 1.1...|\n",
      "| 60|[0.050949614, 0.9...|\n",
      "| 80|[0.24611104, 1.48...|\n",
      "| 90|[0.1574142, 1.202...|\n",
      "|100|[0.23665363, 0.96...|\n",
      "|110|[0.19942038, 1.19...|\n",
      "|120|[0.4508344, 1.090...|\n",
      "|130|[0.71206963, 0.42...|\n",
      "|150|[0.020531598, 0.9...|\n",
      "|160|[-0.01816241, 1.1...|\n",
      "|170|[0.41517526, 1.34...|\n",
      "|180|[0.05407523, 0.86...|\n",
      "|190|[-0.19890136, 0.8...|\n",
      "|200|[0.12387429, 0.86...|\n",
      "|210|[-0.009281533, 1....|\n",
      "|220|[-0.8095619, -0.0...|\n",
      "|230|[-0.07211917, 0.5...|\n",
      "|240|[0.0368624, 1.022...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.itemFactors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1938:>                                                       (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.2344622964227925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(best_model.transform(test_set))\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2118:>                                                       (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.2213078815765972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter = 15, rank = best_model.rank, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "training_model = als.fit(train_set)\n",
    "\n",
    "predictions = training_model.transform(test_set)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter = 20, rank = best_model.rank, userCol=\"user_id\", itemCol=\"anime_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "training_model = als.fit(train_set)\n",
    "\n",
    "predictions = training_model.transform(test_set)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
